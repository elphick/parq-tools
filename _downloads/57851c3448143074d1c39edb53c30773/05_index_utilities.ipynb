{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# Index Utilities\n\nA simple example to demonstrate utilities related to `index` columns.\n\n<div class=\"alert alert-info\"><h4>Note</h4><p>Index columns as we know them in Pandas do not exist in a native Parquet file.  However, if the Parquet file\n    has been created using Pandas then metadata is preserved to restore the indexes when a round-trip back to Pandas\n    is completed.</p></div>\n\nThe utilities demonstrated here are tools mimic index operations that one may use in Pandas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import tempfile\n\nimport pandas as pd\nimport pyarrow as pa\nimport pyarrow.dataset as ds\nfrom pathlib import Path\n\nfrom parq_tools import sort_parquet_file, reindex_parquet, validate_index_alignment\nfrom parq_tools.utils.demo_block_model import create_demo_blockmodel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create a dataset\n\nCreate a temporary parquet file for demonstration.  This example represents a 3D block model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "parquet_file_path = Path(tempfile.gettempdir()) / \"example_data.parquet\"\n\ndf: pd.DataFrame = create_demo_blockmodel(shape=(3, 3, 3), block_size=(1, 1, 1),\n                                          corner=(-0.5, -0.5, -0.5))\ndf.to_parquet(parquet_file_path)\ndf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Randomise the order of the DataFrame and persist to Parquet\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = df.sample(frac=1)\ndf.to_parquet(parquet_file_path)\ndf_randomised = pd.read_parquet(parquet_file_path)\ndf_randomised"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Sort by the index\n\nWe can sort the DataFrame by the index columns to mimic the behavior of Pandas.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "index_cols = [\"x\", \"y\", \"z\"]\nsorted_file_path: Path = parquet_file_path.parent / \"sorted_example_data.parquet\"\nsort_parquet_file(parquet_file_path, output_path=sorted_file_path,\n                  columns=index_cols, chunk_size=100_000)\n\n# Read the sorted Parquet file\nsorted_df = pd.read_parquet(sorted_file_path)\nsorted_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reindexing\nWe can reindex the DataFrame to change the order of the index columns.  This is useful if we want to change the\norder of the index columns to align with another dataset prior to concatenation.  Reindexing will reorder existing\nrecords, and will add empty records if the new index has more records than the original index.\n\nTo demonstrate this, we will create another Parquet file with a subset of the original records that are unordered.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "unsorted_subset_file_path: Path = parquet_file_path.parent / \"unsorted_subset.parquet\"\ndf_randomised.sample(frac=0.5).to_parquet(unsorted_subset_file_path)\ndf_unsorted_subset: pd.DataFrame = pd.read_parquet(unsorted_subset_file_path)\ndf_unsorted_subset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Reindex the unsorted subset to match the original index order\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "reindexed_file_path: Path = parquet_file_path.parent / \"reindexed_subset.parquet\"\nreindex_parquet(unsorted_subset_file_path, output_path=reindexed_file_path,\n                new_index=pa.Table.from_pandas(sorted_df.reset_index()[index_cols]))\ndf_reindexed: pd.DataFrame = pd.read_parquet(reindexed_file_path).set_index(index_cols)\ndf_reindexed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validate index alignment\nWe can demonstrate the `validate_index_alignment` function.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "datasets: list[ds.Dataset] = [ds.dataset(pf) for pf in [sorted_file_path, reindexed_file_path]]\nvalidate_index_alignment(datasets=datasets, index_columns=index_cols)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}